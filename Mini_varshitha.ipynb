{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32b111b1-2eb8-47ab-a6e5-06a2da11793b",
   "metadata": {},
   "source": [
    "# Mini Project - Modified ResNet Architecture with CIFAR-10 images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d4fc4a-2d31-4d28-8d4d-d10c58954d33",
   "metadata": {},
   "source": [
    "**Goal:** In this mini-project we are tasked with coming up with a modified residual network (ResNet)\n",
    "architecture with the **highest test accuracy** on the CIFAR-10 image classification dataset, under the\n",
    "constraint that our model has **no more than 5 million parameters**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943cffb1-00cc-491b-bce8-3834f85234c5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Dataset loading and importing packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbcd6a0-7b50-408d-aabb-bc89ca2cf4b5",
   "metadata": {},
   "source": [
    "We are using **Amazon SageMaker Studio Lab** for this mini-project and so there are a lot of packages to download. Additionally, we would be using **CIFAR-10 image classification dataset** which has the classes: ‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’, ‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’. The images in CIFAR-10 are of size 3x32x32, i.e. 3-channel color images of 32x32 pixels in size. This dataset can be loaded using the **torchvision** package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35e12e67-3869-489a-ac75-9f65715a7c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Requirement already satisfied: torch==1.10.0+cu111 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (1.10.0+cu111)\n",
      "Requirement already satisfied: torchvision==0.11.1+cu111 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (0.11.1+cu111)\n",
      "Requirement already satisfied: typing-extensions in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch==1.10.0+cu111) (4.4.0)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torchvision==0.11.1+cu111) (9.3.0)\n",
      "Requirement already satisfied: numpy in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torchvision==0.11.1+cu111) (1.23.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Installing Packages - Pytorch and Torchvision\n",
    "%pip install torch==1.10.0+cu111 torchvision==0.11.1+cu111 -f https://download.pytorch.org/whl/torch_stable.html --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03cc8916-7df4-4e77-bf47-6b007ccba079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbe89794-a7ed-46e0-9400-1abf8c69486e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Loading and Transforming dataset\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# Train dataset and loader\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "# Test dataset and loader\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "# Target classes\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10af65d6-7d95-4ae1-acc2-4128f1f4981e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Define our device as the first visible cuda device if we have CUDA available\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37eb8574-bf76-4900-a6c8-2623a44a7265",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Define a ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f006fd05-cae1-44bd-b3ef-0af9f62658b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchsummary in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (1.5.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Installing and Importing Libraries\n",
    "%pip install torchsummary \n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e756502f-55d0-4744-94fb-77b7e0a8d9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dabfb6c7-1695-420a-a185-df11ef337767",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlockKernel(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlockKernel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=1, stride=stride, padding=0, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=1,\n",
    "                               stride=1, padding=0, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e2130e4-994b-4dc8-98f2-ec44d1e91cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
    "                               planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e48f6f-1d5a-4231-8b4b-fb6a8060ef19",
   "metadata": {},
   "source": [
    "Created a custom Resnet function to test all configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f77f8ad-9221-4d01-ac24-60ecfd4c3fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_channels = [64, 128, 256, 512], strides = [1, 2, 2, 2], linear_in= 512, in_planes = 64, avg_pool_size = 4, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = in_planes\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, in_planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        self.layers_list = []\n",
    "        for i in range(len(num_blocks)):\n",
    "            # Makes layers based on the num_blocks, num_channels, strides given\n",
    "            self.layers_list.append(self._make_layer(block, num_channels[i], num_blocks[i], stride=strides[i]))\n",
    "        self.layer1 = nn.Sequential(*self.layers_list)\n",
    "        self.linear = nn.Linear(linear_in*block.expansion, num_classes)\n",
    "        self.avg_pool_size = avg_pool_size\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = F.avg_pool2d(out, self.avg_pool_size)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0364e9b1-3c8f-4fae-937a-1e7aa52990c3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Testing different configurations of Resnet-18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a7c1ac-8393-4dfe-b363-8d918c79327a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Setting up different configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa801dc-04bb-4176-b9c2-c4278f43c1c3",
   "metadata": {},
   "source": [
    "Experimented with:\n",
    "\n",
    "Configuration 1 - Reducing number of blocks\n",
    "\n",
    "Configuration 2 - Reducing number of layers and blocks with bottleneck\n",
    "\n",
    "Configuration 3 - Reducing number of layers, blocks and increasing number of channels\n",
    "\n",
    "Configuration 4 - Reducing number of layers, blocks, increasing number of channels and modifying average pool kernel size \n",
    "\n",
    "Configuration 5 - Changing number of blocks, kernel size of a block in  the residual layer and avg pool kernel size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f89daa84-b428-4b77-936c-5efe35ce99eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "            Conv2d-3           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-4           [-1, 64, 32, 32]             128\n",
      "            Conv2d-5           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 32, 32]             128\n",
      "        BasicBlock-7           [-1, 64, 32, 32]               0\n",
      "            Conv2d-8           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 32, 32]             128\n",
      "           Conv2d-10           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-11           [-1, 64, 32, 32]             128\n",
      "       BasicBlock-12           [-1, 64, 32, 32]               0\n",
      "           Conv2d-13          [-1, 128, 16, 16]          73,728\n",
      "      BatchNorm2d-14          [-1, 128, 16, 16]             256\n",
      "           Conv2d-15          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-16          [-1, 128, 16, 16]             256\n",
      "           Conv2d-17          [-1, 128, 16, 16]           8,192\n",
      "      BatchNorm2d-18          [-1, 128, 16, 16]             256\n",
      "       BasicBlock-19          [-1, 128, 16, 16]               0\n",
      "           Conv2d-20          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-21          [-1, 128, 16, 16]             256\n",
      "           Conv2d-22          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 16, 16]             256\n",
      "       BasicBlock-24          [-1, 128, 16, 16]               0\n",
      "           Conv2d-25            [-1, 256, 8, 8]         294,912\n",
      "      BatchNorm2d-26            [-1, 256, 8, 8]             512\n",
      "           Conv2d-27            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-28            [-1, 256, 8, 8]             512\n",
      "           Conv2d-29            [-1, 256, 8, 8]          32,768\n",
      "      BatchNorm2d-30            [-1, 256, 8, 8]             512\n",
      "       BasicBlock-31            [-1, 256, 8, 8]               0\n",
      "           Conv2d-32            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-33            [-1, 256, 8, 8]             512\n",
      "           Conv2d-34            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-35            [-1, 256, 8, 8]             512\n",
      "       BasicBlock-36            [-1, 256, 8, 8]               0\n",
      "           Conv2d-37            [-1, 512, 4, 4]       1,179,648\n",
      "      BatchNorm2d-38            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-39            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-40            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-41            [-1, 512, 4, 4]         131,072\n",
      "      BatchNorm2d-42            [-1, 512, 4, 4]           1,024\n",
      "       BasicBlock-43            [-1, 512, 4, 4]               0\n",
      "           Conv2d-44            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-45            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-46            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-47            [-1, 512, 4, 4]           1,024\n",
      "       BasicBlock-48            [-1, 512, 4, 4]               0\n",
      "           Linear-49                   [-1, 10]           5,130\n",
      "================================================================\n",
      "Total params: 11,173,962\n",
      "Trainable params: 11,173,962\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 11.25\n",
      "Params size (MB): 42.63\n",
      "Estimated Total Size (MB): 53.89\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Original Resnet-18\n",
    "net = ResNet(BasicBlock, [2, 2, 2, 2], [64, 128, 256, 512], [1, 2, 2, 2])\n",
    "print(summary(net, (3, 32, 32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "771da475-cac4-4358-a125-2a796765e3d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "            Conv2d-3           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-4           [-1, 64, 32, 32]             128\n",
      "            Conv2d-5           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 32, 32]             128\n",
      "        BasicBlock-7           [-1, 64, 32, 32]               0\n",
      "            Conv2d-8           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 32, 32]             128\n",
      "           Conv2d-10           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-11           [-1, 64, 32, 32]             128\n",
      "       BasicBlock-12           [-1, 64, 32, 32]               0\n",
      "           Conv2d-13          [-1, 128, 16, 16]          73,728\n",
      "      BatchNorm2d-14          [-1, 128, 16, 16]             256\n",
      "           Conv2d-15          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-16          [-1, 128, 16, 16]             256\n",
      "           Conv2d-17          [-1, 128, 16, 16]           8,192\n",
      "      BatchNorm2d-18          [-1, 128, 16, 16]             256\n",
      "       BasicBlock-19          [-1, 128, 16, 16]               0\n",
      "           Conv2d-20            [-1, 256, 8, 8]         294,912\n",
      "      BatchNorm2d-21            [-1, 256, 8, 8]             512\n",
      "           Conv2d-22            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-23            [-1, 256, 8, 8]             512\n",
      "           Conv2d-24            [-1, 256, 8, 8]          32,768\n",
      "      BatchNorm2d-25            [-1, 256, 8, 8]             512\n",
      "       BasicBlock-26            [-1, 256, 8, 8]               0\n",
      "           Conv2d-27            [-1, 512, 4, 4]       1,179,648\n",
      "      BatchNorm2d-28            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-29            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-30            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-31            [-1, 512, 4, 4]         131,072\n",
      "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
      "       BasicBlock-33            [-1, 512, 4, 4]               0\n",
      "           Linear-34                   [-1, 10]           5,130\n",
      "================================================================\n",
      "Total params: 4,977,226\n",
      "Trainable params: 4,977,226\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 9.06\n",
      "Params size (MB): 18.99\n",
      "Estimated Total Size (MB): 28.06\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Reducing number of residual blocks\n",
    "net1 = ResNet(BasicBlock, [2, 1, 1, 1], [64, 128, 256, 512], [1, 2, 2, 2])\n",
    "print(summary(net1, (3, 32, 32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79efae3f-fda2-4308-a390-d0236903c6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "            Conv2d-3           [-1, 64, 32, 32]           4,096\n",
      "       BatchNorm2d-4           [-1, 64, 32, 32]             128\n",
      "            Conv2d-5           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 32, 32]             128\n",
      "            Conv2d-7          [-1, 256, 32, 32]          16,384\n",
      "       BatchNorm2d-8          [-1, 256, 32, 32]             512\n",
      "            Conv2d-9          [-1, 256, 32, 32]          16,384\n",
      "      BatchNorm2d-10          [-1, 256, 32, 32]             512\n",
      "       Bottleneck-11          [-1, 256, 32, 32]               0\n",
      "           Conv2d-12           [-1, 64, 32, 32]          16,384\n",
      "      BatchNorm2d-13           [-1, 64, 32, 32]             128\n",
      "           Conv2d-14           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-15           [-1, 64, 32, 32]             128\n",
      "           Conv2d-16          [-1, 256, 32, 32]          16,384\n",
      "      BatchNorm2d-17          [-1, 256, 32, 32]             512\n",
      "       Bottleneck-18          [-1, 256, 32, 32]               0\n",
      "           Conv2d-19           [-1, 64, 32, 32]          16,384\n",
      "      BatchNorm2d-20           [-1, 64, 32, 32]             128\n",
      "           Conv2d-21           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-22           [-1, 64, 32, 32]             128\n",
      "           Conv2d-23          [-1, 256, 32, 32]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 32, 32]             512\n",
      "       Bottleneck-25          [-1, 256, 32, 32]               0\n",
      "           Conv2d-26          [-1, 128, 32, 32]          32,768\n",
      "      BatchNorm2d-27          [-1, 128, 32, 32]             256\n",
      "           Conv2d-28          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 16, 16]             256\n",
      "           Conv2d-30          [-1, 512, 16, 16]          65,536\n",
      "      BatchNorm2d-31          [-1, 512, 16, 16]           1,024\n",
      "           Conv2d-32          [-1, 512, 16, 16]         131,072\n",
      "      BatchNorm2d-33          [-1, 512, 16, 16]           1,024\n",
      "       Bottleneck-34          [-1, 512, 16, 16]               0\n",
      "           Conv2d-35          [-1, 128, 16, 16]          65,536\n",
      "      BatchNorm2d-36          [-1, 128, 16, 16]             256\n",
      "           Conv2d-37          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-38          [-1, 128, 16, 16]             256\n",
      "           Conv2d-39          [-1, 512, 16, 16]          65,536\n",
      "      BatchNorm2d-40          [-1, 512, 16, 16]           1,024\n",
      "       Bottleneck-41          [-1, 512, 16, 16]               0\n",
      "           Conv2d-42          [-1, 128, 16, 16]          65,536\n",
      "      BatchNorm2d-43          [-1, 128, 16, 16]             256\n",
      "           Conv2d-44          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-45          [-1, 128, 16, 16]             256\n",
      "           Conv2d-46          [-1, 512, 16, 16]          65,536\n",
      "      BatchNorm2d-47          [-1, 512, 16, 16]           1,024\n",
      "       Bottleneck-48          [-1, 512, 16, 16]               0\n",
      "           Conv2d-49          [-1, 256, 16, 16]         131,072\n",
      "      BatchNorm2d-50          [-1, 256, 16, 16]             512\n",
      "           Conv2d-51            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-52            [-1, 256, 8, 8]             512\n",
      "           Conv2d-53           [-1, 1024, 8, 8]         262,144\n",
      "      BatchNorm2d-54           [-1, 1024, 8, 8]           2,048\n",
      "           Conv2d-55           [-1, 1024, 8, 8]         524,288\n",
      "      BatchNorm2d-56           [-1, 1024, 8, 8]           2,048\n",
      "       Bottleneck-57           [-1, 1024, 8, 8]               0\n",
      "           Conv2d-58            [-1, 256, 8, 8]         262,144\n",
      "      BatchNorm2d-59            [-1, 256, 8, 8]             512\n",
      "           Conv2d-60            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-61            [-1, 256, 8, 8]             512\n",
      "           Conv2d-62           [-1, 1024, 8, 8]         262,144\n",
      "      BatchNorm2d-63           [-1, 1024, 8, 8]           2,048\n",
      "       Bottleneck-64           [-1, 1024, 8, 8]               0\n",
      "           Conv2d-65            [-1, 256, 8, 8]         262,144\n",
      "      BatchNorm2d-66            [-1, 256, 8, 8]             512\n",
      "           Conv2d-67            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-68            [-1, 256, 8, 8]             512\n",
      "           Conv2d-69           [-1, 1024, 8, 8]         262,144\n",
      "      BatchNorm2d-70           [-1, 1024, 8, 8]           2,048\n",
      "       Bottleneck-71           [-1, 1024, 8, 8]               0\n",
      "           Linear-72                   [-1, 10]          40,970\n",
      "================================================================\n",
      "Total params: 4,944,970\n",
      "Trainable params: 4,944,970\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 52.25\n",
      "Params size (MB): 18.86\n",
      "Estimated Total Size (MB): 71.13\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# residual layer reduction and residual block modification with bottleneck\n",
    "net2 = ResNet(Bottleneck, [3, 3, 3], [64, 128, 256], [1, 2, 2], 1024)\n",
    "print(summary(net2, (3, 32, 32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03ed53bc-0e95-4d53-9c39-9e8bbc41a4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "            Conv2d-3          [-1, 128, 32, 32]          73,728\n",
      "       BatchNorm2d-4          [-1, 128, 32, 32]             256\n",
      "            Conv2d-5          [-1, 128, 32, 32]         147,456\n",
      "       BatchNorm2d-6          [-1, 128, 32, 32]             256\n",
      "            Conv2d-7          [-1, 128, 32, 32]           8,192\n",
      "       BatchNorm2d-8          [-1, 128, 32, 32]             256\n",
      "        BasicBlock-9          [-1, 128, 32, 32]               0\n",
      "           Conv2d-10          [-1, 256, 16, 16]         294,912\n",
      "      BatchNorm2d-11          [-1, 256, 16, 16]             512\n",
      "           Conv2d-12          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-13          [-1, 256, 16, 16]             512\n",
      "           Conv2d-14          [-1, 256, 16, 16]          32,768\n",
      "      BatchNorm2d-15          [-1, 256, 16, 16]             512\n",
      "       BasicBlock-16          [-1, 256, 16, 16]               0\n",
      "           Conv2d-17            [-1, 512, 8, 8]       1,179,648\n",
      "      BatchNorm2d-18            [-1, 512, 8, 8]           1,024\n",
      "           Conv2d-19            [-1, 512, 8, 8]       2,359,296\n",
      "      BatchNorm2d-20            [-1, 512, 8, 8]           1,024\n",
      "           Conv2d-21            [-1, 512, 8, 8]         131,072\n",
      "      BatchNorm2d-22            [-1, 512, 8, 8]           1,024\n",
      "       BasicBlock-23            [-1, 512, 8, 8]               0\n",
      "           Linear-24                   [-1, 10]          20,490\n",
      "================================================================\n",
      "Total params: 4,844,618\n",
      "Trainable params: 4,844,618\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 13.25\n",
      "Params size (MB): 18.48\n",
      "Estimated Total Size (MB): 31.74\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# reducing residual layer, reducing residual block and increasing number of chan modification\n",
    "net3 = ResNet(BasicBlock, [1, 1, 1], [128, 256, 512], [1, 2, 2], 2048)\n",
    "print(summary(net3, (3, 32, 32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8b4c7ac-8c00-426b-aedc-72a9e757d44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "            Conv2d-3          [-1, 128, 32, 32]          73,728\n",
      "       BatchNorm2d-4          [-1, 128, 32, 32]             256\n",
      "            Conv2d-5          [-1, 128, 32, 32]         147,456\n",
      "       BatchNorm2d-6          [-1, 128, 32, 32]             256\n",
      "            Conv2d-7          [-1, 128, 32, 32]           8,192\n",
      "       BatchNorm2d-8          [-1, 128, 32, 32]             256\n",
      "        BasicBlock-9          [-1, 128, 32, 32]               0\n",
      "           Conv2d-10          [-1, 256, 16, 16]         294,912\n",
      "      BatchNorm2d-11          [-1, 256, 16, 16]             512\n",
      "           Conv2d-12          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-13          [-1, 256, 16, 16]             512\n",
      "           Conv2d-14          [-1, 256, 16, 16]          32,768\n",
      "      BatchNorm2d-15          [-1, 256, 16, 16]             512\n",
      "       BasicBlock-16          [-1, 256, 16, 16]               0\n",
      "           Conv2d-17            [-1, 512, 8, 8]       1,179,648\n",
      "      BatchNorm2d-18            [-1, 512, 8, 8]           1,024\n",
      "           Conv2d-19            [-1, 512, 8, 8]       2,359,296\n",
      "      BatchNorm2d-20            [-1, 512, 8, 8]           1,024\n",
      "           Conv2d-21            [-1, 512, 8, 8]         131,072\n",
      "      BatchNorm2d-22            [-1, 512, 8, 8]           1,024\n",
      "       BasicBlock-23            [-1, 512, 8, 8]               0\n",
      "           Linear-24                   [-1, 10]          81,930\n",
      "================================================================\n",
      "Total params: 4,906,058\n",
      "Trainable params: 4,906,058\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 13.25\n",
      "Params size (MB): 18.72\n",
      "Estimated Total Size (MB): 31.98\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# reducing residual layer, reducing residual block, increasing number of channels, modifying average pool kernel size \n",
    "net4 = ResNet(BasicBlock, [1, 1, 1], [128, 256, 512], [1, 2, 2], 8192, avg_pool_size = 2)\n",
    "print(summary(net4, (3, 32, 32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82745615-527f-41b7-af70-4778f70b399a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "            Conv2d-3           [-1, 64, 32, 32]           4,096\n",
      "       BatchNorm2d-4           [-1, 64, 32, 32]             128\n",
      "            Conv2d-5           [-1, 64, 32, 32]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 32, 32]             128\n",
      "  BasicBlockKernel-7           [-1, 64, 32, 32]               0\n",
      "            Conv2d-8           [-1, 64, 32, 32]           4,096\n",
      "       BatchNorm2d-9           [-1, 64, 32, 32]             128\n",
      "           Conv2d-10           [-1, 64, 32, 32]           4,096\n",
      "      BatchNorm2d-11           [-1, 64, 32, 32]             128\n",
      " BasicBlockKernel-12           [-1, 64, 32, 32]               0\n",
      "           Conv2d-13           [-1, 64, 32, 32]           4,096\n",
      "      BatchNorm2d-14           [-1, 64, 32, 32]             128\n",
      "           Conv2d-15           [-1, 64, 32, 32]           4,096\n",
      "      BatchNorm2d-16           [-1, 64, 32, 32]             128\n",
      " BasicBlockKernel-17           [-1, 64, 32, 32]               0\n",
      "           Conv2d-18           [-1, 64, 32, 32]           4,096\n",
      "      BatchNorm2d-19           [-1, 64, 32, 32]             128\n",
      "           Conv2d-20           [-1, 64, 32, 32]           4,096\n",
      "      BatchNorm2d-21           [-1, 64, 32, 32]             128\n",
      " BasicBlockKernel-22           [-1, 64, 32, 32]               0\n",
      "           Conv2d-23           [-1, 64, 32, 32]           4,096\n",
      "      BatchNorm2d-24           [-1, 64, 32, 32]             128\n",
      "           Conv2d-25           [-1, 64, 32, 32]           4,096\n",
      "      BatchNorm2d-26           [-1, 64, 32, 32]             128\n",
      " BasicBlockKernel-27           [-1, 64, 32, 32]               0\n",
      "           Conv2d-28           [-1, 64, 32, 32]           4,096\n",
      "      BatchNorm2d-29           [-1, 64, 32, 32]             128\n",
      "           Conv2d-30           [-1, 64, 32, 32]           4,096\n",
      "      BatchNorm2d-31           [-1, 64, 32, 32]             128\n",
      " BasicBlockKernel-32           [-1, 64, 32, 32]               0\n",
      "           Conv2d-33           [-1, 64, 32, 32]           4,096\n",
      "      BatchNorm2d-34           [-1, 64, 32, 32]             128\n",
      "           Conv2d-35           [-1, 64, 32, 32]           4,096\n",
      "      BatchNorm2d-36           [-1, 64, 32, 32]             128\n",
      " BasicBlockKernel-37           [-1, 64, 32, 32]               0\n",
      "           Conv2d-38           [-1, 64, 32, 32]           4,096\n",
      "      BatchNorm2d-39           [-1, 64, 32, 32]             128\n",
      "           Conv2d-40           [-1, 64, 32, 32]           4,096\n",
      "      BatchNorm2d-41           [-1, 64, 32, 32]             128\n",
      " BasicBlockKernel-42           [-1, 64, 32, 32]               0\n",
      "           Conv2d-43          [-1, 128, 16, 16]           8,192\n",
      "      BatchNorm2d-44          [-1, 128, 16, 16]             256\n",
      "           Conv2d-45          [-1, 128, 16, 16]          16,384\n",
      "      BatchNorm2d-46          [-1, 128, 16, 16]             256\n",
      "           Conv2d-47          [-1, 128, 16, 16]           8,192\n",
      "      BatchNorm2d-48          [-1, 128, 16, 16]             256\n",
      " BasicBlockKernel-49          [-1, 128, 16, 16]               0\n",
      "           Conv2d-50          [-1, 128, 16, 16]          16,384\n",
      "      BatchNorm2d-51          [-1, 128, 16, 16]             256\n",
      "           Conv2d-52          [-1, 128, 16, 16]          16,384\n",
      "      BatchNorm2d-53          [-1, 128, 16, 16]             256\n",
      " BasicBlockKernel-54          [-1, 128, 16, 16]               0\n",
      "           Conv2d-55          [-1, 128, 16, 16]          16,384\n",
      "      BatchNorm2d-56          [-1, 128, 16, 16]             256\n",
      "           Conv2d-57          [-1, 128, 16, 16]          16,384\n",
      "      BatchNorm2d-58          [-1, 128, 16, 16]             256\n",
      " BasicBlockKernel-59          [-1, 128, 16, 16]               0\n",
      "           Conv2d-60          [-1, 128, 16, 16]          16,384\n",
      "      BatchNorm2d-61          [-1, 128, 16, 16]             256\n",
      "           Conv2d-62          [-1, 128, 16, 16]          16,384\n",
      "      BatchNorm2d-63          [-1, 128, 16, 16]             256\n",
      " BasicBlockKernel-64          [-1, 128, 16, 16]               0\n",
      "           Conv2d-65          [-1, 128, 16, 16]          16,384\n",
      "      BatchNorm2d-66          [-1, 128, 16, 16]             256\n",
      "           Conv2d-67          [-1, 128, 16, 16]          16,384\n",
      "      BatchNorm2d-68          [-1, 128, 16, 16]             256\n",
      " BasicBlockKernel-69          [-1, 128, 16, 16]               0\n",
      "           Conv2d-70          [-1, 128, 16, 16]          16,384\n",
      "      BatchNorm2d-71          [-1, 128, 16, 16]             256\n",
      "           Conv2d-72          [-1, 128, 16, 16]          16,384\n",
      "      BatchNorm2d-73          [-1, 128, 16, 16]             256\n",
      " BasicBlockKernel-74          [-1, 128, 16, 16]               0\n",
      "           Conv2d-75          [-1, 128, 16, 16]          16,384\n",
      "      BatchNorm2d-76          [-1, 128, 16, 16]             256\n",
      "           Conv2d-77          [-1, 128, 16, 16]          16,384\n",
      "      BatchNorm2d-78          [-1, 128, 16, 16]             256\n",
      " BasicBlockKernel-79          [-1, 128, 16, 16]               0\n",
      "           Conv2d-80            [-1, 256, 8, 8]          32,768\n",
      "      BatchNorm2d-81            [-1, 256, 8, 8]             512\n",
      "           Conv2d-82            [-1, 256, 8, 8]          65,536\n",
      "      BatchNorm2d-83            [-1, 256, 8, 8]             512\n",
      "           Conv2d-84            [-1, 256, 8, 8]          32,768\n",
      "      BatchNorm2d-85            [-1, 256, 8, 8]             512\n",
      " BasicBlockKernel-86            [-1, 256, 8, 8]               0\n",
      "           Conv2d-87            [-1, 256, 8, 8]          65,536\n",
      "      BatchNorm2d-88            [-1, 256, 8, 8]             512\n",
      "           Conv2d-89            [-1, 256, 8, 8]          65,536\n",
      "      BatchNorm2d-90            [-1, 256, 8, 8]             512\n",
      " BasicBlockKernel-91            [-1, 256, 8, 8]               0\n",
      "           Conv2d-92            [-1, 256, 8, 8]          65,536\n",
      "      BatchNorm2d-93            [-1, 256, 8, 8]             512\n",
      "           Conv2d-94            [-1, 256, 8, 8]          65,536\n",
      "      BatchNorm2d-95            [-1, 256, 8, 8]             512\n",
      " BasicBlockKernel-96            [-1, 256, 8, 8]               0\n",
      "           Conv2d-97            [-1, 256, 8, 8]          65,536\n",
      "      BatchNorm2d-98            [-1, 256, 8, 8]             512\n",
      "           Conv2d-99            [-1, 256, 8, 8]          65,536\n",
      "     BatchNorm2d-100            [-1, 256, 8, 8]             512\n",
      "BasicBlockKernel-101            [-1, 256, 8, 8]               0\n",
      "          Conv2d-102            [-1, 256, 8, 8]          65,536\n",
      "     BatchNorm2d-103            [-1, 256, 8, 8]             512\n",
      "          Conv2d-104            [-1, 256, 8, 8]          65,536\n",
      "     BatchNorm2d-105            [-1, 256, 8, 8]             512\n",
      "BasicBlockKernel-106            [-1, 256, 8, 8]               0\n",
      "          Conv2d-107            [-1, 256, 8, 8]          65,536\n",
      "     BatchNorm2d-108            [-1, 256, 8, 8]             512\n",
      "          Conv2d-109            [-1, 256, 8, 8]          65,536\n",
      "     BatchNorm2d-110            [-1, 256, 8, 8]             512\n",
      "BasicBlockKernel-111            [-1, 256, 8, 8]               0\n",
      "          Conv2d-112            [-1, 256, 8, 8]          65,536\n",
      "     BatchNorm2d-113            [-1, 256, 8, 8]             512\n",
      "          Conv2d-114            [-1, 256, 8, 8]          65,536\n",
      "     BatchNorm2d-115            [-1, 256, 8, 8]             512\n",
      "BasicBlockKernel-116            [-1, 256, 8, 8]               0\n",
      "          Conv2d-117            [-1, 512, 4, 4]         131,072\n",
      "     BatchNorm2d-118            [-1, 512, 4, 4]           1,024\n",
      "          Conv2d-119            [-1, 512, 4, 4]         262,144\n",
      "     BatchNorm2d-120            [-1, 512, 4, 4]           1,024\n",
      "          Conv2d-121            [-1, 512, 4, 4]         131,072\n",
      "     BatchNorm2d-122            [-1, 512, 4, 4]           1,024\n",
      "BasicBlockKernel-123            [-1, 512, 4, 4]               0\n",
      "          Conv2d-124            [-1, 512, 4, 4]         262,144\n",
      "     BatchNorm2d-125            [-1, 512, 4, 4]           1,024\n",
      "          Conv2d-126            [-1, 512, 4, 4]         262,144\n",
      "     BatchNorm2d-127            [-1, 512, 4, 4]           1,024\n",
      "BasicBlockKernel-128            [-1, 512, 4, 4]               0\n",
      "          Conv2d-129            [-1, 512, 4, 4]         262,144\n",
      "     BatchNorm2d-130            [-1, 512, 4, 4]           1,024\n",
      "          Conv2d-131            [-1, 512, 4, 4]         262,144\n",
      "     BatchNorm2d-132            [-1, 512, 4, 4]           1,024\n",
      "BasicBlockKernel-133            [-1, 512, 4, 4]               0\n",
      "          Conv2d-134            [-1, 512, 4, 4]         262,144\n",
      "     BatchNorm2d-135            [-1, 512, 4, 4]           1,024\n",
      "          Conv2d-136            [-1, 512, 4, 4]         262,144\n",
      "     BatchNorm2d-137            [-1, 512, 4, 4]           1,024\n",
      "BasicBlockKernel-138            [-1, 512, 4, 4]               0\n",
      "          Conv2d-139            [-1, 512, 4, 4]         262,144\n",
      "     BatchNorm2d-140            [-1, 512, 4, 4]           1,024\n",
      "          Conv2d-141            [-1, 512, 4, 4]         262,144\n",
      "     BatchNorm2d-142            [-1, 512, 4, 4]           1,024\n",
      "BasicBlockKernel-143            [-1, 512, 4, 4]               0\n",
      "          Conv2d-144            [-1, 512, 4, 4]         262,144\n",
      "     BatchNorm2d-145            [-1, 512, 4, 4]           1,024\n",
      "          Conv2d-146            [-1, 512, 4, 4]         262,144\n",
      "     BatchNorm2d-147            [-1, 512, 4, 4]           1,024\n",
      "BasicBlockKernel-148            [-1, 512, 4, 4]               0\n",
      "          Conv2d-149            [-1, 512, 4, 4]         262,144\n",
      "     BatchNorm2d-150            [-1, 512, 4, 4]           1,024\n",
      "          Conv2d-151            [-1, 512, 4, 4]         262,144\n",
      "     BatchNorm2d-152            [-1, 512, 4, 4]           1,024\n",
      "BasicBlockKernel-153            [-1, 512, 4, 4]               0\n",
      "          Linear-154                   [-1, 10]          81,930\n",
      "================================================================\n",
      "Total params: 4,995,146\n",
      "Trainable params: 4,995,146\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 37.19\n",
      "Params size (MB): 19.05\n",
      "Estimated Total Size (MB): 56.25\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# changing number of residual blocks, kernel size of a block in residual layer and avg pool kernel size\n",
    "net5 = ResNet(BasicBlockKernel, [8, 7, 7, 7], [64, 128, 256, 512], [1, 2, 2, 2], 8192, avg_pool_size = 1)\n",
    "print(summary(net5, (3, 32, 32)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b24dd91-0a6c-4a3b-983b-097861dece53",
   "metadata": {},
   "source": [
    "### Training and Testing them to compare performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ac3d9ba-bab9-4ed2-891b-32b2b4bae4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01d2b2bd-1bfc-46b3-8897-952d7c8b3af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "net4 = net4.to(device)\n",
    "if device == 'cuda':\n",
    "    net4 = torch.nn.DataParallel(net4)\n",
    "    cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ebe2d5d-2596-443d-8adf-6f1481fc2216",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b85bad8-a9fd-4877-a452-ce830d7b3efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters())\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93aca501-0df5-4669-8722-1e4e749295bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4,906,058\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "parameters=count_parameters(net4)\n",
    "print(f\"{parameters:,}\")\n",
    "assert parameters<5000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0938e49a-307c-4bc9-89aa-52c4faf9e4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6fbd62d2-4e99-4a28-b613-8fb6366faf00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_76/836698695.py\u001b[0m in \u001b[0;36m<cell line: 57>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_epoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnet4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnet4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_76/836698695.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, net)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_76/3847572300.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg_pool_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_76/2588164160.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshortcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    440\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 442\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    443\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training\n",
    "\n",
    "def train(epoch,net):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "\n",
    "def test(epoch,net):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net': net.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('checkpoint')\n",
    "        torch.save(state, './checkpoint/ckpt.pth')\n",
    "        best_acc = acc\n",
    "    print('Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                            % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "full_start_time = time.time()\n",
    "\n",
    "for epoch in range(start_epoch, start_epoch+20):\n",
    "    start_time = time.time()\n",
    "    train(epoch,net4)\n",
    "    test(epoch,net4)\n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    print(f\"Time Elapsed: {epoch_mins}m {epoch_secs}s\")\n",
    "    scheduler.step()\n",
    "\n",
    "full_end_time = time.time()\n",
    "full_mins, full_secs = epoch_time(full_start_time, full_end_time)\n",
    "print(f\"Total time elapsed: {full_mins}m {full_secs}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd23425d-cce8-4d35-8b36-4b1c9f234ae4",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d98e019-7774-4b5a-9ddb-d5dbc6213a38",
   "metadata": {},
   "source": [
    "1. https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "2. https://github.com/kuangliu/pytorch-cifar"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
